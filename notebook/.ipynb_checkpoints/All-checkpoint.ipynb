{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "497e6f86-65ca-4b8a-8482-596b3059cd62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ 'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n",
      "WARNING ⚠️ 'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n",
      "Note this warning may be related to loading older models. You can update your model to current structure with:\n",
      "    import torch\n",
      "    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n",
      "    torch.save(ckpt, \"updated-model.pt\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#First : Importing Libraries\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "from ultralytics.yolo.utils.plotting import Annotator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1594c23-0036-4e54-9e40-d85a658b2638",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second : Function : Return the predication\n",
    "def predict_image(image):\n",
    "    results = model.predict(image,show_conf=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1c57acc-5a83-423f-a489-0d242cbaca02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Third : Function : Shows the image with boxes around the things and doesn't return anything\n",
    "def show_image_after_classification(results,image,model):\n",
    "    for r in results:    \n",
    "            annotator = Annotator(image)\n",
    "            boxes = r.boxes\n",
    "            for box in boxes:\n",
    "                if(box.conf > 0.6):\n",
    "                    b = box.xyxy[0] \n",
    "                    c = box.cls\n",
    "                    x = box\n",
    "                    annotator.box_label(b, model.names[int(c)])\n",
    "    image = annotator.result()\n",
    "    output_image_path = os.path.join(image_path)\n",
    "    cv2.imwrite(output_image_path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5f98cce-fb43-4959-8d23-beff38f8179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fourth : Function Crops the image with each data type alone:\n",
    "def Crop_types(results,image,model):\n",
    "    types = {\"shirts\": [], \"jeans\" : [],\"sandals\":[]}\n",
    "    for r in results:    \n",
    "            annotator = Annotator(image)\n",
    "            boxes = r.boxes\n",
    "            for box in boxes:\n",
    "                if(box.conf > 0.6):\n",
    "                    b = box.xyxy[0] \n",
    "                    c = box.cls\n",
    "                    top, left, bottom, right = map(int, b)\n",
    "                    cropped_image = image[left:right, top:bottom]\n",
    "                    types[model.names[int(c)]].append(cropped_image)\n",
    "    return types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39a3ce78-6dc3-49d0-9d24-ad3bcea7a286",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fifth : Amro's Task and ahmed's task , which is siamse and entering in the image\n",
    "def Siamase(types):\n",
    "    for type in types:\n",
    "        for num in range(0,len(types[type])):\n",
    "            image = types[type][num]\n",
    "            cv2.imwrite(f\"x{num} {type}.jpg\", image)\n",
    "            ###Code Amr : Implement function and call it ya amr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "405f3782-c822-4c03-bced-85dd8b85348f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x448 1 jeans, 185.4ms\n",
      "Speed: 13.0ms preprocess, 185.4ms inference, 18.0ms postprocess per image at shape (1, 3, 640, 448)\n"
     ]
    }
   ],
   "source": [
    "#Main:\n",
    "image_path = \"1.jpg\"\n",
    "image = cv2.imread(image_path)\n",
    "model_path = \"../data/best.pt\"    \n",
    "model = YOLO(model_path)\n",
    "results = predict_image(image)\n",
    "show_image_after_classification(results,image,model)\n",
    "types = Crop_types(results,image,model)\n",
    "Siamase(types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90a3aed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'jeans', 1: 'shirts', 2: 'jackets', 3: 'shoes'}\n",
       " orig_img: array([[[247, 247, 247],\n",
       "         [247, 247, 247],\n",
       "         [247, 247, 247],\n",
       "         ...,\n",
       "         [247, 247, 247],\n",
       "         [247, 247, 247],\n",
       "         [247, 247, 247]],\n",
       " \n",
       "        [[247, 247, 247],\n",
       "         [247, 247, 247],\n",
       "         [247, 247, 247],\n",
       "         ...,\n",
       "         [247, 247, 247],\n",
       "         [247, 247, 247],\n",
       "         [247, 247, 247]],\n",
       " \n",
       "        [[247, 247, 247],\n",
       "         [247, 247, 247],\n",
       "         [247, 247, 247],\n",
       "         ...,\n",
       "         [247, 247, 247],\n",
       "         [247, 247, 247],\n",
       "         [247, 247, 247]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[247, 247, 247],\n",
       "         [247, 247, 247],\n",
       "         [247, 247, 247],\n",
       "         ...,\n",
       "         [247, 247, 247],\n",
       "         [247, 247, 247],\n",
       "         [247, 247, 247]],\n",
       " \n",
       "        [[247, 247, 247],\n",
       "         [247, 247, 247],\n",
       "         [247, 247, 247],\n",
       "         ...,\n",
       "         [247, 247, 247],\n",
       "         [247, 247, 247],\n",
       "         [247, 247, 247]],\n",
       " \n",
       "        [[247, 247, 247],\n",
       "         [247, 247, 247],\n",
       "         [247, 247, 247],\n",
       "         ...,\n",
       "         [247, 247, 247],\n",
       "         [247, 247, 247],\n",
       "         [247, 247, 247]]], dtype=uint8)\n",
       " orig_shape: (2529, 1686)\n",
       " path: 'image0.jpg'\n",
       " probs: None\n",
       " save_dir: None\n",
       " speed: {'preprocess': 12.977838516235352, 'inference': 185.3923797607422, 'postprocess': 17.986297607421875}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95014439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1976796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef94beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stores = [\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d30f6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for type in os.listdir(\"../database/images\"):\n",
    "    for image in os.listdir(\"../database/images\" + \"/\" + type):\n",
    "        file_name_without_extension = os.path.splitext(image)[0]\n",
    "        x = file_name_without_extension\n",
    "        random_price = np.round(np.random.uniform(10.0, 100.0, 1))\n",
    "        random_integers = np.random.randint(1, 50, size=1)\n",
    "        with open(\"../database/info/\" + type + \"/\" + x + \".txt\", 'w') as file:\n",
    "            file.write(\"Store: store\")\n",
    "            file.write(str(random_integers[0]))\n",
    "            file.write(\"\\n\")\n",
    "            file.write(\"Price(dollars): \")\n",
    "            file.write(str(random_price[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ba50b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_amounts = np.round(np.random.uniform(10.0, 100.0, 1))\n",
    "random_amounts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b788dbe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_integers = np.random.randint(1, 50, size=1)\n",
    "random_integers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35ab39b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
